{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS\n",
    "# -----------------------------\n",
    "base_dir    = r\"E:/SLIIT/Year 2 Semester 1/IT2011 - Artficial Intelligence and Machine Learning/Assignment/WildFireDetection/data/raw\"\n",
    "resize_dir  = r\"E:/SLIIT/Year 2 Semester 1/IT2011 - Artficial Intelligence and Machine Learning/Assignment/WildFireDetection/results/outputs/group_pipeline/resized\"\n",
    "color_dir   = r\"E:/SLIIT/Year 2 Semester 1/IT2011 - Artficial Intelligence and Machine Learning/Assignment/WildFireDetection/results/outputs/group_pipeline/color_balanced\"\n",
    "denoise_dir = r\"E:/SLIIT/Year 2 Semester 1/IT2011 - Artficial Intelligence and Machine Learning/Assignment/WildFireDetection/results/outputs/group_pipeline/denoised\"\n",
    "aug_dir     = r\"E:/SLIIT/Year 2 Semester 1/IT2011 - Artficial Intelligence and Machine Learning/Assignment/WildFireDetection/results/outputs/group_pipeline/augmented\"\n",
    "edge_dir    = r\"E:/SLIIT/Year 2 Semester 1/IT2011 - Artficial Intelligence and Machine Learning/Assignment/WildFireDetection/results/outputs/group_pipeline/edge\"\n",
    "norm_dir    = r\"E:/SLIIT/Year 2 Semester 1/IT2011 - Artficial Intelligence and Machine Learning/Assignment/WildFireDetection/results/outputs/group_pipeline/normalized\"\n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "classes = ['fire', 'nofire']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# TRANSFORMS\n",
    "to_tensor = transforms.ToTensor()\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "# Normalization transform\n",
    "normalize_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Gaussian blur for denoising\n",
    "gaussian_blur = transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "\n",
    "# Augmentations\n",
    "fire_aug = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.7),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "])\n",
    "\n",
    "nofire_aug = A.Compose([\n",
    "    A.Rotate(limit=15, p=0.3),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "])\n",
    "\n",
    "\n",
    "# 1. RESIZE by Sanchala K.A.N (IT24100260)\n",
    "\n",
    "print(\"\\n=== RESIZING IMAGES ===\")\n",
    "\n",
    "for split in splits:\n",
    "    for cls in classes:\n",
    "        input_path = os.path.join(base_dir, split, cls)\n",
    "        output_path = os.path.join(resize_dir, split, cls)\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        img_files = [f for f in os.listdir(input_path) if f.endswith('.jpg')]\n",
    "        \n",
    "        for img_name in tqdm(img_files, desc=f\"Resizing {split}/{cls}\", unit=\"img\"):\n",
    "            img = Image.open(os.path.join(input_path, img_name)).convert(\"RGB\")\n",
    "            \n",
    "            # Resize transform\n",
    "            resize_transform = transforms.Compose([\n",
    "                transforms.Resize((600, 600)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            \n",
    "            img_tensor = resize_transform(img).to(device)\n",
    "            \n",
    "            # Save resized image\n",
    "            img_pil = to_pil_image(img_tensor.cpu())\n",
    "            img_pil.save(os.path.join(output_path, img_name))\n",
    "\n",
    "# 2. COLOR BALANCE by Rajapakshe R.P.P.S (IT24100368)\n",
    "\n",
    "print(\"\\n=== COLOR BALANCING ===\")\n",
    "\n",
    "for split in splits:\n",
    "    for cls in classes:\n",
    "        in_path  = os.path.join(resize_dir, split, cls)\n",
    "        out_path = os.path.join(color_dir, split, cls)\n",
    "        os.makedirs(out_path, exist_ok=True)\n",
    "        \n",
    "        img_files = [f for f in os.listdir(in_path) if f.endswith('.jpg')]\n",
    "        \n",
    "        for img_name in tqdm(img_files, desc=f\"Color balancing {split}/{cls}\", unit=\"img\"):\n",
    "            try:\n",
    "\n",
    "                img = cv2.imread(os.path.join(in_path, img_name))\n",
    "                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n",
    "                balanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "                cv2.imwrite(os.path.join(out_path, img_name), balanced)\n",
    "\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\" Error processing {img_name}: {e}\")\n",
    "\n",
    "# 3. DENOISE + ENHANCE by Vithanage M.M (IT24100288)\n",
    "\n",
    "print(\"\\n=== DENOISING AND ENHANCEMENT ===\")\n",
    "\n",
    "for split in splits:\n",
    "    for cls in classes:\n",
    "        input_path = os.path.join(color_dir, split, cls)\n",
    "        output_path = os.path.join(denoise_dir, split, cls)\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        img_files = [f for f in os.listdir(input_path) if f.endswith('.jpg')]\n",
    "        \n",
    "        for img_name in tqdm(img_files, desc=f\"Denoising {split}/{cls}\", unit=\"img\"):\n",
    "\n",
    "            try:\n",
    "                img = Image.open(os.path.join(input_path, img_name)).convert(\"RGB\")\n",
    "                img_tensor = to_tensor(img).to(device)\n",
    "                \n",
    "                # Apply denoising (Gaussian blur)\n",
    "                img_denoised = gaussian_blur(img_tensor.unsqueeze(0)).squeeze(0)\n",
    "                \n",
    "                # Apply enhancement (CLAHE)\n",
    "                img_np = (img_denoised.cpu().permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "                lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "                lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "                enhanced_np = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "                img_enhanced = torch.from_numpy(enhanced_np).permute(2, 0, 1).float() / 255.0\n",
    "                \n",
    "                # Save result\n",
    "                to_pil_image(img_enhanced.cpu()).save(os.path.join(output_path, img_name))\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error with {img_name}: {e}\")\n",
    "\n",
    "\n",
    "# 4. DATA AUGMENTATION by Nimneth P.B.Y (IT24100304)\n",
    "\n",
    "print(\"\\n=== DATA AUGMENTATION ===\")\n",
    "\n",
    "for split in splits:\n",
    "    for cls in classes:\n",
    "        input_path = os.path.join(denoise_dir, split, cls)\n",
    "        output_path = os.path.join(aug_dir, split, cls)\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        img_files = [f for f in os.listdir(input_path) if f.endswith('.jpg')]\n",
    "        \n",
    "        if split == 'train':\n",
    "            # Class balancing logic\n",
    "            fire_count = len([f for f in os.listdir(os.path.join(denoise_dir, split, 'fire')) if f.endswith('.jpg')])\n",
    "            nofire_count = len([f for f in os.listdir(os.path.join(denoise_dir, split, 'nofire')) if f.endswith('.jpg')])\n",
    "            target_size = max(fire_count, nofire_count)\n",
    "            needed = target_size - len(img_files)\n",
    "            \n",
    "            # Select augmentation pipeline\n",
    "            aug_transform = fire_aug if cls == 'fire' else nofire_aug\n",
    "            \n",
    "            # Save originals first\n",
    "            for img_name in img_files:\n",
    "                img = Image.open(os.path.join(input_path, img_name)).convert(\"RGB\")\n",
    "                img.save(os.path.join(output_path, img_name))\n",
    "            \n",
    "            # Augment until class is balanced\n",
    "            i = 0\n",
    "            while i < needed:\n",
    "                for img_name in img_files:\n",
    "                    if i >= needed:\n",
    "                        break\n",
    "\n",
    "                    try:\n",
    "                        img = Image.open(os.path.join(input_path, img_name)).convert(\"RGB\")\n",
    "                        img_np = np.array(img)\n",
    "                        augmented = aug_transform(image=img_np)['image']\n",
    "                        aug_img = Image.fromarray(augmented)\n",
    "                        save_name = f\"aug_{i}_{img_name}\"\n",
    "                        aug_img.save(os.path.join(output_path, save_name))\n",
    "                        i += 1\n",
    "                    except Exception as e:\n",
    "                        tqdm.write(f\"⚠️ Error processing {img_name}: {e}\")\n",
    "\n",
    "        else:\n",
    "            # For val/test just copy images\n",
    "            for img_name in img_files:\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(input_path, img_name)).convert(\"RGB\")\n",
    "                    img.save(os.path.join(output_path, img_name))\n",
    "                except Exception as e:\n",
    "                    tqdm.write(f\"⚠️ Error processing {img_name}: {e}\")\n",
    "\n",
    "\n",
    "# 5. EDGE DETECTION by Perera B.P.N (IT24100327)\n",
    "\n",
    "print(\"\\n=== EDGE DETECTION ===\")\n",
    "\n",
    "for split in splits:\n",
    "    for cls in classes:\n",
    "        in_path  = os.path.join(aug_dir, split, cls)\n",
    "        out_path = os.path.join(edge_dir, split, cls)\n",
    "        os.makedirs(out_path, exist_ok=True)\n",
    "        \n",
    "        img_files = [f for f in os.listdir(in_path) if f.endswith('.jpg')]\n",
    "        \n",
    "        for img_name in tqdm(img_files, desc=f\"Edge detection {split}/{cls}\", unit=\"img\"):\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(os.path.join(in_path, img_name))\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Edge detection (Sobel)\n",
    "                sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "                sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "                sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "                sobel = np.uint8(np.clip(sobel, 0, 255))\n",
    "                \n",
    "                # Save edge map as JPG\n",
    "                cv2.imwrite(os.path.join(out_path, img_name), sobel)\n",
    "\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\" Error processing {img_name}: {e}\")\n",
    "            \n",
    "\n",
    "# 6. NORMALIZATION by Thaveesha L.H.K (IT24100368)\n",
    "\n",
    "print(\"\\n=== NORMALIZATION ===\")\n",
    "\n",
    "for split in splits:\n",
    "    for cls in classes:\n",
    "        input_path = os.path.join(aug_dir, split, cls)\n",
    "        output_path = os.path.join(norm_dir, split, cls)\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        img_files = [f for f in os.listdir(input_path) if f.endswith('.jpg')]\n",
    "        \n",
    "        for img_name in tqdm(img_files, desc=f\"Normalizing {split}/{cls}\", unit=\"img\"):\n",
    "            try: \n",
    "                img = Image.open(os.path.join(input_path, img_name)).convert(\"RGB\")\n",
    "                \n",
    "                # Normalize\n",
    "                img_norm = normalize_transform(img).to(device)\n",
    "                \n",
    "                # Save normalized image (reversed for visualization)\n",
    "                img_save = img_norm * torch.tensor([0.229, 0.224, 0.225], device=device).view(3, 1, 1) + \\\n",
    "                        torch.tensor([0.485, 0.456, 0.406], device=device).view(3, 1, 1)\n",
    "                img_save = img_save.clamp(0, 1)\n",
    "                img_save = to_pil_image(img_save.cpu())\n",
    "                img_save.save(os.path.join(output_path, img_name))\n",
    "\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\" Error processing {img_name}: {e}\")\n",
    "\n",
    "print(\"\\n=== PIPELINE COMPLETE ===\")\n",
    "print(\"All processing steps finished successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
